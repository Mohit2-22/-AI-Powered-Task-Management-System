{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e853b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First 5 Rows ---\n",
      "    bugID                                                 sd  \\\n",
      "0  550000            PDE quickfix creates invalid @Since tag   \n",
      "1  550001  Grant access to projects storage service to th...   \n",
      "2  550002               Add relation information to REST-API   \n",
      "3  550003  Provide platform independent plug-in to set th...   \n",
      "4  550004  Inline method refacting reports \"Inaccurate re...   \n",
      "\n",
      "                   cl         pd          co   rp     os        bs  \\\n",
      "0     Eclipse Project        PDE   API Tools   PC  Linux  VERIFIED   \n",
      "1  Eclipse Foundation  Community  CI-Jenkins   PC  Linux    CLOSED   \n",
      "2          Automotive      MDMBL     General  All    All    CLOSED   \n",
      "3     Eclipse Project   Platform          UI   PC  Linux    CLOSED   \n",
      "4     Eclipse Project        JDT          UI   PC  Linux  RESOLVED   \n",
      "\n",
      "           rs  pr     bsr  \n",
      "0       FIXED  P3  normal  \n",
      "1   DUPLICATE  P3  normal  \n",
      "2       FIXED  P3   major  \n",
      "3   DUPLICATE  P3  normal  \n",
      "4  WORKSFORME  P3  normal  \n",
      "\n",
      "--- Column Names ---\n",
      "Index(['bugID', 'sd', 'cl', 'pd', 'co', 'rp', 'os', 'bs', 'rs', 'pr', 'bsr'], dtype='object')\n",
      "\n",
      "--- Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8478 entries, 0 to 8477\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   bugID   8478 non-null   int64 \n",
      " 1   sd      8478 non-null   object\n",
      " 2   cl      8478 non-null   object\n",
      " 3   pd      8478 non-null   object\n",
      " 4   co      8478 non-null   object\n",
      " 5   rp      8478 non-null   object\n",
      " 6   os      8478 non-null   object\n",
      " 7   bs      8478 non-null   object\n",
      " 8   rs      7363 non-null   object\n",
      " 9   pr      8478 non-null   object\n",
      " 10  bsr     8478 non-null   object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 728.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file.\n",
    "# Note: This file uses a semicolon (;) as a delimiter, not a comma.\n",
    "file_path = r\"C:\\projects\\Zaalima_Development_project\\bugreports\\Eclipse.csv\"\n",
    "df = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# See the first 5 rows\n",
    "print(\"--- First 5 Rows ---\")\n",
    "print(df.head())\n",
    "\n",
    "# See all the column names\n",
    "print(\"\\n--- Column Names ---\")\n",
    "print(df.columns)\n",
    "\n",
    "# See the data summary (to check for missing values, etc.)\n",
    "print(\"\\n--- Data Info ---\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f74b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saaf Kiya Hua Data (Cleaned Data) ---\n",
      "                                             Summary    Product Priority\n",
      "0            PDE quickfix creates invalid @Since tag        PDE       P3\n",
      "1  Grant access to projects storage service to th...  Community       P3\n",
      "2               Add relation information to REST-API      MDMBL       P3\n",
      "3  Provide platform independent plug-in to set th...   Platform       P3\n",
      "4  Inline method refacting reports \"Inaccurate re...        JDT       P3\n",
      "\n",
      "--- Cleaned Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8478 entries, 0 to 8477\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Summary   8478 non-null   object\n",
      " 1   Product   8478 non-null   object\n",
      " 2   Priority  8478 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 198.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.rename(columns={\n",
    "    'sd': 'Summary',\n",
    "    'pd': 'Product',\n",
    "    'pr': 'Priority'\n",
    "}, inplace=True)\n",
    "\n",
    "# Description column is missing so we will use Summary as our main text\n",
    "df_cleaned = df[['Summary', 'Product', 'Priority']]\n",
    "\n",
    "\n",
    "print(\"\\n--- Saaf Kiya Hua Data (Cleaned Data) ---\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "\n",
    "print(\"\\n--- Cleaned Data Info ---\")\n",
    "print(df_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a392770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking NLTK data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\A__I\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\A__I\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data is ready.\n",
      "\n",
      "--- Loading and Cleaning Data ---\n",
      "Loading data from: c:\\projects\\Zaalima_Development_project\\bugreports\\Eclipse.csv\n",
      "Data has been loaded and initial cleaning is done.\n",
      "                                             Summary    Product Priority\n",
      "0            PDE quickfix creates invalid @Since tag        PDE       P3\n",
      "1  Grant access to projects storage service to th...  Community       P3\n",
      "2               Add relation information to REST-API      MDMBL       P3\n",
      "3  Provide platform independent plug-in to set th...   Platform       P3\n",
      "4  Inline method refacting reports \"Inaccurate re...        JDT       P3\n",
      "\n",
      "--- Applying NLP Preprocessing ---\n",
      "Preprocessing complete.\n",
      "\n",
      "--- Training Task Classifier Model ---\n",
      "\n",
      "Product distribution:\n",
      "Product\n",
      "Capella             1678\n",
      "Platform            1455\n",
      "Community           1107\n",
      "JDT                  784\n",
      "Kitalpha             429\n",
      "                    ... \n",
      "WTP Common Tools       1\n",
      "basyx                  1\n",
      "STEM                   1\n",
      "EMFT.Henshin           1\n",
      "Mylyn Commons          1\n",
      "Name: count, Length: 135, dtype: int64\n",
      "\n",
      "Removed 121 samples from classes with less than 5 instances\n",
      "Classifier Model has been trained.\n",
      "\n",
      "--- Classification Report for Product Prediction ---\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                    3p       0.00      0.00      0.00         1\n",
      "                 4DIAC       1.00      0.10      0.19        39\n",
      "               Amalgam       0.00      0.00      0.00         1\n",
      "                App4mc       0.00      0.00      0.00         3\n",
      "               AspectJ       0.00      0.00      0.00         5\n",
      "                  BIRT       0.00      0.00      0.00         8\n",
      "                 Babel       0.00      0.00      0.00         3\n",
      "             Buildship       0.00      0.00      0.00         1\n",
      "                   CBI       0.00      0.00      0.00         4\n",
      "                   CDT       0.00      0.00      0.00        33\n",
      "               Capella       0.45      0.92      0.61       336\n",
      "                 Capra       0.00      0.00      0.00         1\n",
      "                   Che       0.00      0.00      0.00         1\n",
      "             Community       0.73      0.83      0.78       222\n",
      "                  DLTK       0.00      0.00      0.00         1\n",
      "                   ECF       0.00      0.00      0.00         2\n",
      "                   ECP       0.00      0.00      0.00        14\n",
      "                  EGit       0.00      0.00      0.00        36\n",
      "                   EMF       0.00      0.00      0.00        10\n",
      "         EMF.Diffmerge       0.00      0.00      0.00         2\n",
      "               EMF.EGF       0.00      0.00      0.00         1\n",
      "            EMFCompare       0.00      0.00      0.00         1\n",
      "                   EPP       0.00      0.00      0.00         8\n",
      "                   ESF       0.00      0.00      0.00         1\n",
      "                  Ease       0.00      0.00      0.00        15\n",
      "           EclipseLink       0.00      0.00      0.00         5\n",
      "               Epsilon       0.00      0.00      0.00         2\n",
      "               Equinox       0.00      0.00      0.00        23\n",
      "                   GEF       0.00      0.00      0.00         3\n",
      "                Handly       0.00      0.00      0.00         1\n",
      "                   JDT       0.68      0.55      0.61       157\n",
      "                  JGit       0.00      0.00      0.00        15\n",
      "                  JSDT       0.00      0.00      0.00         2\n",
      "                Jubula       0.00      0.00      0.00         1\n",
      "              Kitalpha       1.00      0.12      0.21        86\n",
      "           Linux Tools       0.00      0.00      0.00         4\n",
      "               M2E-WTP       0.00      0.00      0.00         1\n",
      "                   MAT       0.00      0.00      0.00         4\n",
      "                 MDMBL       0.00      0.00      0.00         6\n",
      "                   MPC       0.00      0.00      0.00         4\n",
      "               MoDisco       0.00      0.00      0.00         3\n",
      "                 Mylyn       0.00      0.00      0.00         2\n",
      "            Mylyn Docs       0.00      0.00      0.00         2\n",
      "              NatTable       0.00      0.00      0.00         5\n",
      "                   OCL       0.00      0.00      0.00         5\n",
      "           Objectteams       0.00      0.00      0.00         6\n",
      "                 Oomph       0.00      0.00      0.00        14\n",
      "                 Orbit       0.00      0.00      0.00         7\n",
      "                 Orion       0.00      0.00      0.00         1\n",
      "                   PDE       0.00      0.00      0.00        35\n",
      "               Papyrus       0.83      0.11      0.20        44\n",
      "               Passage       1.00      0.31      0.47        26\n",
      "              Platform       0.43      0.85      0.57       291\n",
      "                  QVTd       0.00      0.00      0.00         8\n",
      "                  QVTo       0.00      0.00      0.00         1\n",
      "                   RAP       0.00      0.00      0.00         4\n",
      "                 RCPTT       0.00      0.00      0.00         3\n",
      "              Reqcycle       0.00      0.00      0.00         9\n",
      "                SWTBot       0.00      0.00      0.00         2\n",
      "                Sirius       0.00      0.00      0.00        18\n",
      "                Statet       0.00      0.00      0.00         8\n",
      "                   TMF       0.00      0.00      0.00         2\n",
      "          Tracecompass       0.00      0.00      0.00        10\n",
      "Tracecompass.Incubator       0.00      0.00      0.00         1\n",
      "                Viatra       0.00      0.00      0.00         4\n",
      "     WTP Java EE Tools       0.00      0.00      0.00         1\n",
      "       WTP ServerTools       0.00      0.00      0.00         1\n",
      "    WTP Source Editing       0.00      0.00      0.00         3\n",
      "        Working Groups       0.00      0.00      0.00         1\n",
      "                   XWT       0.00      0.00      0.00         1\n",
      "                    e4       0.00      0.00      0.00         2\n",
      "                eTrice       0.00      0.00      0.00         8\n",
      "                 lsp4e       0.00      0.00      0.00        11\n",
      "                openj9       0.00      0.00      0.00         1\n",
      "            z_Archived       1.00      0.03      0.06        69\n",
      "\n",
      "              accuracy                           0.51      1672\n",
      "             macro avg       0.09      0.05      0.05      1672\n",
      "          weighted avg       0.48      0.51      0.41      1672\n",
      "\n",
      "\n",
      "Models saved in: c:\\projects\\Zaalima_Development_project\\jupyterNotebook\n",
      "TF-IDF Vectorizer and Classifier Model have been saved!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 1. SETUP: Import Libraries and Download NLTK Data\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import joblib\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Download required NLTK data (only needs to be run once)\n",
    "print(\"--- Checking NLTK data ---\")\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "try:\n",
    "    nltk.word_tokenize('test')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('punkt_tab')  # Add this line to download punkt_tab\n",
    "print(\"NLTK data is ready.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. DATA LOADING AND CLEANING\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Loading and Cleaning Data ---\")\n",
    "# Load the dataset\n",
    "\n",
    "# Set the correct file path\n",
    "file_path = os.path.join(os.path.dirname(os.getcwd()), \"bugreports\", \"Eclipse.csv\")\n",
    "if not os.path.exists(file_path):\n",
    "    # Try alternate path if first one doesn't exist\n",
    "    file_path = os.path.join(os.getcwd(), \"bugreports\", \"Eclipse.csv\")\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"The file 'Eclipse.csv' was not found at {file_path}.\\n\"\n",
    "        \"Please ensure the file exists in the bugreports directory.\"\n",
    "    )\n",
    "\n",
    "print(f\"Loading data from: {file_path}\")\n",
    "df = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Rename the important columns to be more readable\n",
    "df.rename(columns={\n",
    "    'sd': 'Summary',\n",
    "    'pd': 'Product',\n",
    "    'pr': 'Priority'\n",
    "}, inplace=True)\n",
    "\n",
    "# Select only the columns we need and create a clean copy\n",
    "# Using .copy() here is important to avoid the SettingWithCopyWarning\n",
    "df_cleaned = df[['Summary', 'Product', 'Priority']].copy()\n",
    "print(\"Data has been loaded and initial cleaning is done.\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. NLP PREPROCESSING\n",
    "# ==============================================================================\n",
    "# Define the preprocessing function\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', str(text))  # Remove non-alphanumeric characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove stopwords and apply stemming\n",
    "    processed_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(processed_tokens)\n",
    "\n",
    "# Apply the function to the 'Summary' column\n",
    "print(\"\\n--- Applying NLP Preprocessing ---\")\n",
    "df_cleaned['processed_text'] = df_cleaned['Summary'].apply(preprocess_text)\n",
    "print(\"Preprocessing complete.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. MODEL 1: TASK CLASSIFIER (Product Prediction)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Training Task Classifier Model ---\")\n",
    "# Define features (X) and target (y)\n",
    "X = df_cleaned['processed_text']\n",
    "y = df_cleaned['Product']\n",
    "\n",
    "# Count samples per class\n",
    "class_counts = y.value_counts()\n",
    "print(\"\\nProduct distribution:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Filter out classes with too few samples (less than 5)\n",
    "min_samples = 5\n",
    "valid_classes = class_counts[class_counts >= min_samples].index\n",
    "mask = y.isin(valid_classes)\n",
    "\n",
    "# Filter X and y to keep only classes with sufficient samples\n",
    "X_filtered = X[mask]\n",
    "y_filtered = y[mask]\n",
    "\n",
    "print(f\"\\nRemoved {len(y) - len(y_filtered)} samples from classes with less than {min_samples} instances\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_filtered, test_size=0.2, random_state=42, stratify=y_filtered)\n",
    "\n",
    "# Create and fit the TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=3000)\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "classifier_model = MultinomialNB()\n",
    "classifier_model.fit(X_train_vec, y_train)\n",
    "print(\"Classifier Model has been trained.\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = classifier_model.predict(X_test_vec)\n",
    "print(\"\\n--- Classification Report for Product Prediction ---\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Save the model and vectorizer in the current working directory\n",
    "model_dir = os.getcwd()\n",
    "tfidf_path = os.path.join(model_dir, 'tfidf_vectorizer.joblib')\n",
    "model_path = os.path.join(model_dir, 'classifier_model.joblib')\n",
    "\n",
    "joblib.dump(tfidf, tfidf_path)\n",
    "joblib.dump(classifier_model, model_path)\n",
    "print(f\"\\nModels saved in: {model_dir}\")\n",
    "print(\"TF-IDF Vectorizer and Classifier Model have been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bbfaa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Priority Predictor Model ---\n",
      "TF-IDF Vectorizer loaded and data transformed.\n",
      "Priority Model has been trained.\n",
      "\n",
      "--- Classification Report for Priority Prediction ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.00      0.00      0.00         8\n",
      "          P2       1.00      0.08      0.15        24\n",
      "          P3       0.95      1.00      0.97      1609\n",
      "          P4       0.20      0.02      0.03        54\n",
      "          P5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95      1696\n",
      "   macro avg       0.43      0.22      0.23      1696\n",
      "weighted avg       0.92      0.95      0.93      1696\n",
      "\n",
      "\n",
      "Priority Model has been saved!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# --- Model 2: Priority Predictor ---\n",
    "print(\"\\n--- Training Priority Predictor Model ---\")\n",
    "\n",
    "# The 'df_cleaned' DataFrame is already available from the previous steps\n",
    "\n",
    "# 1. Define your features (X) and new target (y)\n",
    "X = df_cleaned['processed_text']\n",
    "y = df_cleaned['Priority']  # This time the target is Priority\n",
    "\n",
    "# 2. Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 3. Load the previously saved TF-IDF Vectorizer\n",
    "# We use the same vectorizer to keep the features consistent\n",
    "tfidf = joblib.load('tfidf_vectorizer.joblib')\n",
    "X_train_vec = tfidf.transform(X_train)\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "print(\"TF-IDF Vectorizer loaded and data transformed.\")\n",
    "\n",
    "# 4. Train the Random Forest Classifier model\n",
    "# RandomForest is a good choice for this kind of problem\n",
    "priority_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "priority_model.fit(X_train_vec, y_train)\n",
    "print(\"Priority Model has been trained.\")\n",
    "\n",
    "# 5. Evaluate the model\n",
    "y_pred = priority_model.predict(X_test_vec)\n",
    "print(\"\\n--- Classification Report for Priority Prediction ---\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# 6. Save the priority model\n",
    "joblib.dump(priority_model, 'priority_model.joblib')\n",
    "print(\"\\nPriority Model has been saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
